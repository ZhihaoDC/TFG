{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "marvel_social_network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZhihaoDC/TFG/blob/main/marvel_social_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpCgOrz6DcFR"
      },
      "source": [
        "#Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IK-xiBIDVns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a9d0595-5f8a-4e59-e580-9fe9d3a31126"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "%cd /gdrive/My Drive/TFG\n",
        "\n",
        "!git pull https://github.com/ZhihaoDC/TFG"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/My Drive/TFG\n",
            "From https://github.com/ZhihaoDC/TFG\n",
            " * branch            HEAD       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv2hNXaqDfHK"
      },
      "source": [
        "#Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QoirQpzDmzC",
        "outputId": "5f68b875-94d9-4dba-e15c-68837cd40227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "import sys\n",
        "\n",
        "from collections import deque, Counter\n",
        "\n",
        "from pyvis.network import Network\n",
        "import IPython\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# import matplotlib.colors as mcolors\n",
        "# import seaborn as sns\n",
        "\n",
        "# import statistics\n",
        "# import math\n",
        "# import itertools\n",
        "# import re #regular expressions\n",
        "\n",
        "# import plotly.express as px\n",
        "# import plotly.figure_factory as ff"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1c87e6297fe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeque\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyvis'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0JIKuBjktjT"
      },
      "source": [
        "#Read files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejKgv_GTmDb2"
      },
      "source": [
        "*   **nodes**: Node name and type.\n",
        "*   **edges**: Heroes and the comic in which they appear.\n",
        "*   ***heroes***: Edges between heroes that appear in the same comic."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzEDDvLfkv1p",
        "outputId": "1ab76c72-e3af-4ac1-f64e-8a85027a55f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "nodes = pd.read_csv('./datasets/marvel-social-network/nodes.csv') #Node name and type\n",
        "edges = pd.read_csv('./datasets/marvel-social-network/edges.csv') #Heroes and the comic in which they appear\n",
        "heroes = pd.read_csv('./datasets/marvel-social-network/hero-network.csv') # Edges between heroes that appear in the same comic"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-4e205626ca56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./datasets/marvel-social-network/nodes.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Node name and type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./datasets/marvel-social-network/edges.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Heroes and the comic in which they appear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mheroes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./datasets/marvel-social-network/hero-network.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Edges between heroes that appear in the same comic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './datasets/marvel-social-network/nodes.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-bjJpRv6qTr"
      },
      "source": [
        "##Show basic info on dataframes:\n",
        "\n",
        "# nodes.info() #190.090 rows, 2 columns, no null values\n",
        "# print('\\n')\n",
        "# edges.info() #96.104 rows, 2 columns, no null values\n",
        "# print('\\n')\n",
        "# heroes.info() #574.467 rows, 2 columns, no null values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJetcMDcnWsn"
      },
      "source": [
        "##Peek into the dataframes:\n",
        "\n",
        "# nodes.head(10)\n",
        "# edges.head(10)\n",
        "heroes.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPWynhxE3SjT"
      },
      "source": [
        "#Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggaObAtk3c4b"
      },
      "source": [
        "#Remove leading and trailing spaces\n",
        "\n",
        "nodes = nodes.applymap(lambda x: x.strip())\n",
        "edges = edges.applymap(lambda x: x.strip())\n",
        "heroes = heroes.applymap(lambda x: x.strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N7_8ba5bkrS"
      },
      "source": [
        "#Graph exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQr8CJHcqejD"
      },
      "source": [
        "#Number of times IronMan/TonyStark has appeared in another hero's comic\n",
        "heroes.loc[ heroes['hero1']=='IRON MAN/TONY STARK' ].shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z50QDXlmM5I"
      },
      "source": [
        "# Number of times Spiderman/PeterParker appeared in the same comic as IronMan/TonyStark\n",
        "heroes.loc[ (heroes['hero1']=='SPIDER-MAN/PETER PAR') & (heroes['hero2']=='IRON MAN/TONY STARK') ].shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_lvKwmXn1cV"
      },
      "source": [
        "# Number of times IronMan/TonyStark appeared in the same comic as Spiderman/PeterParker\n",
        "heroes.loc[ (heroes['hero1'] == 'IRON MAN/TONY STARK') & (heroes['hero2'] == 'SPIDER-MAN/PETER PAR') ].shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8Z2rzmDo8DJ"
      },
      "source": [
        "These two values may be different because of the structure of the edgelist. Maybe a relationship of (hero1=Spiderman, hero2=Ironman) indicates an occurence of Spiderman appearing in an Ironman comic."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cio06kKcrMS7"
      },
      "source": [
        "#Number different comics in which IronMan/TonyStark has appeared in \n",
        "ironman_h1 = heroes.loc[heroes['hero1'] == 'IRON MAN/TONY STARK'].drop_duplicates()\n",
        "ironman_h1.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnx-nq3ira-B"
      },
      "source": [
        "#Number different heroes that have appeared in a IronMan/TonyStark comic\n",
        "ironman_h2 = heroes.loc[heroes['hero2'] == 'IRON MAN/TONY STARK'].drop_duplicates()\n",
        "ironman_h2.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke_k6xfMrplY"
      },
      "source": [
        "#Number of times IronMan has been involved in his or other heroes' comics\n",
        "ironman_merge = pd.merge(ironman_h1, ironman_h2, how='outer', left_on='hero2', right_on='hero1')\n",
        "ironman_merge.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEbfIZ21px5g"
      },
      "source": [
        "Since we are interested in a non directed graph, we will ignore this fact for the moment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptqpPisf82r2"
      },
      "source": [
        "heroes = heroes.drop_duplicates()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldzS5MFmxXhL"
      },
      "source": [
        "#Generate graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aACGetsT1C4X"
      },
      "source": [
        "#Generate Undirected Graph structure\n",
        "\n",
        "graph = nx.from_pandas_edgelist(heroes, source='hero1', target='hero2') \n",
        "graph = graph.to_undirected(graph) # Unweighted undirected graph\n",
        "\n",
        "print(nx.info(graph))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVaxHVVq31D9"
      },
      "source": [
        "The graph density of simple graphs is defined to be the ratio of the number of edges ${\\displaystyle |E|}$ with respect to the maximum possible edges\n",
        "For undirected simple graphs, the graph density is:\n",
        "\n",
        "${\\displaystyle D={\\frac {|E|}{\\binom {|V|}{2}}}={\\frac {2|E|}{|V|(|V|-1)}}}$\n",
        "\n",
        "where E is the number of edges and V is the number of vertices in the graph.\n",
        "\n",
        " The maximum number of edges for an undirected graph is ${\\displaystyle {\\binom {|V|}{2}}={\\frac{|V|(|V|-1)}{2}}}$, so the maximal density is 1 (for complete graphs) and the minimal density is 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EglLOcYY2wEJ"
      },
      "source": [
        "def graph_density(n_vertex, n_edges):\n",
        "  return (2*n_edges / (n_vertex * (n_vertex - 1)) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLN1R2y_2z-i"
      },
      "source": [
        "density = graph_density(graph.number_of_nodes(), graph.number_of_edges())\n",
        "print(density)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdZ461kSxoMz"
      },
      "source": [
        "#Check graph generation\n",
        "\n",
        "# #Previously seen:\n",
        "# #Number of times IronMan has been involved in his or other heroes' comics\n",
        "# ironman_merge = pd.merge(ironman_h1, ironman_h2, how='outer', left_on='hero2', right_on='hero1')\n",
        "# ironman_merge.shape[0] \n",
        "# #Out: 1521\n",
        "\n",
        "len(list(graph.edges('IRON MAN/TONY STARK')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cAwOpTt__tz"
      },
      "source": [
        "graph_nodes = graph.nodes()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwbzGRfeAxL8"
      },
      "source": [
        "graph_edges = graph.edges()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3SRX8eY8NbB"
      },
      "source": [
        "#Generate subgraph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-FRxLr9VCfi"
      },
      "source": [
        "sort_degrees = sorted(list(graph.degree), key= lambda degree: degree[1], reverse= True)\n",
        "print(sort_degrees)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfhv7sIMZSAE"
      },
      "source": [
        "#Create subgraph with k greatest degree nodes\n",
        "\n",
        "#Get top k greatest degree nodes\n",
        "k = 500\n",
        "greatest_kdeg = []\n",
        "for node, degree in sort_degrees[:k]:\n",
        "  greatest_kdeg.append(node)\n",
        "\n",
        "#Generate subgraph\n",
        "subgraph = graph.subgraph(greatest_kdeg)\n",
        "print(nx.info(subgraph))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbh_cAui5hv7"
      },
      "source": [
        "# net = Network(notebook=True)\n",
        "# net.from_nx(subgraph)\n",
        "# net.repulsion(node_distance=500)\n",
        "# net.inherit_edge_colors(True)\n",
        "# net.save_graph('marvel-network-subgraph.html')\n",
        "# IPython.display.HTML(filename='marvel-network-subgraph.html')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyo0A2tLVhh0"
      },
      "source": [
        "# plt.figure(figsize=(10,10))\n",
        "# nx.draw_networkx(subgraph)\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu24LrqaBhpf"
      },
      "source": [
        "#Girvan-Newman"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMMNEcR2dasG"
      },
      "source": [
        "##Shortest paths (BFS)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQGH7c-zdeXv"
      },
      "source": [
        "def shortest_paths(graph, start):\n",
        "  \"\"\" Get all distances from the 'start' node and its path to all nodes in the graph \n",
        "\n",
        "      Returns:\n",
        "          distances: dict(node, shortest_distance_from_start),\n",
        "          parents: path from node to start as dict(node,predecessor),\n",
        "          num_shortest_paths: dict(node, num_shortest_paths_from_start)\n",
        "  \"\"\"\n",
        "  #visited list to avoid loops\n",
        "  visited= []\n",
        "\n",
        "  #distances from each node to the 'start' node\n",
        "  distances = dict ( [(node, sys.maxsize) for node in graph.nodes()] ) \n",
        "\n",
        "  #predecessors from each node to the 'start' node \n",
        "  parents =  dict ( [(node, []) for node in graph.nodes()] )\n",
        "\n",
        "  #number of shortest paths\n",
        "  num_shortest_paths = dict ( [(node, []) for node in graph.nodes()] )\n",
        "\n",
        "  #initialize before loop\n",
        "  distances[start] = 0\n",
        "  parents[start] = None\n",
        "  num_shortest_paths[start] = 1\n",
        "\n",
        "  #queue data structure for BFS\n",
        "  queue = deque()\n",
        "  queue.append(start)\n",
        "\n",
        "  #mark 'start' as visited\n",
        "  visited.append(start)\n",
        "\n",
        "  while (len(queue) != 0):\n",
        "    visiting = queue.popleft() #visit the first element of the queue (remove it)\n",
        "    visited.append(visiting) #mark as visited\n",
        "\n",
        "    for adj in graph.adj[visiting]: #iterate through adjacent nodes\n",
        "      if (adj not in visited) and (adj not in queue):\n",
        "        queue.append(adj) #add not visited nodes to queue\n",
        "\n",
        "      #if 'adj' node has been visited before and has a longer path that using '\n",
        "      #visiting' as predecessor --> update it (this is the shortest path)\n",
        "\n",
        "      #if 'adj' node has not been visited before, it will always enter this 'if'\n",
        "      #because distances are initialized as sys.maxsize\n",
        "      if (distances[adj] > distances[visiting] + 1): \n",
        "        distances[adj] = distances[visiting] + 1\n",
        "        parents[adj].clear()\n",
        "        parents[adj].append(visiting)\n",
        "        num_shortest_paths[adj] = num_shortest_paths[visiting]\n",
        "\n",
        "\n",
        "      #if 'adj' node has the same distance than 'visiting' + 1, it means we have\n",
        "      #encountered another shortest path --> add 'visiting' as parent in \n",
        "      #the shortest path\n",
        "      elif (distances[adj] == distances[visiting] + 1):\n",
        "        parents[adj].append(visiting)\n",
        "        num_shortest_paths[adj] += num_shortest_paths[visiting]\n",
        "\n",
        "  #End of algorithm, return results\n",
        "  return distances, parents, num_shortest_paths\n",
        "\n",
        "# ### Test code\n",
        "# distances, parents, num_shortest_paths = shortest_paths(graph, 'CAPTAIN AMERICA')\n",
        "# distances\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRiP3PxHdg6g"
      },
      "source": [
        "##Edge betweenness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyW3j_lGdjSh"
      },
      "source": [
        "def get_edge_betweenness(graph, start):\n",
        "  \"\"\"\n",
        "  Get edge betweenness of all edges given source node 'start' \n",
        "  \"\"\"\n",
        "\n",
        "  edges_btwnss = dict([(edge, 0) for edge in graph.edges()])\n",
        "  node_betweenness = dict([(node, 0) for node in graph.nodes()])\n",
        "  \n",
        "  distances, parents, num_shortest_paths = shortest_paths(graph, start) \n",
        "\n",
        "  #furthest nodes from the selected node\n",
        "  furthest_nodes = sorted(distances, key=distances.get, reverse=True)\n",
        "\n",
        "  for node in furthest_nodes:\n",
        "    if node != start:\n",
        "      for parent in parents[node]:\n",
        "        node_betweenness[parent] += (1 + node_betweenness[parent]) / len(parents[node])\n",
        "        if (node, parent) in edges_btwnss:\n",
        "          edges_btwnss[node,parent] = (1 + node_betweenness[node]) / num_shortest_paths[node]\n",
        "        elif (parent,node) in edges_btwnss:\n",
        "          edges_btwnss[parent,node] = (1 + node_betweenness[node]) / num_shortest_paths[node]\n",
        "\n",
        "  return edges_btwnss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeGwOXHSbMVF"
      },
      "source": [
        "def get_edge_betweenness(graph, start):\n",
        "  \"\"\"\n",
        "  Get edge betweenness of all edges given source node 'start' \n",
        "  \"\"\"\n",
        "\n",
        "  edges_btwnss = dict.fromkeys(graph.edges,0)\n",
        "  node_betweenness = dict.fromkeys(graph.nodes, 0)\n",
        "  \n",
        "  distances, parents, num_shortest_paths = shortest_paths(graph, start) \n",
        "\n",
        "  #furthest nodes from the selected node\n",
        "  furthest_nodes = sorted(distances, key=distances.get, reverse=True)\n",
        "\n",
        "  for node in furthest_nodes:\n",
        "    if node !=start:\n",
        "      for parent in parents[node]:\n",
        "        if node == furthest_nodes[0]:\n",
        "          node_betweenness.update({parent: 1 / num_shortest_paths[node]}) \n",
        "          if (node, parent) in edges_btwnss:\n",
        "            edges_btwnss.update({(node, parent): 1 / num_shortest_paths[node]})\n",
        "          elif (parent,node) in edges_btwnss:\n",
        "             edges_btwnss.update({(parent, node): 1 / num_shortest_paths[node]})\n",
        "\n",
        "        else:\n",
        "          btwnnss = (1 + node_betweenness[node]) / num_shortest_paths[node]\n",
        "          \n",
        "          if (node, parent) in edges_btwnss:\n",
        "            edges_btwnss.update({(node, parent):  btwnnss})\n",
        "            node_betweenness.update({parent: node_betweenness[node] + btwnnss} )\n",
        "\n",
        "          elif (parent,node) in edges_btwnss:\n",
        "            edges_btwnss.update({(parent, node): btwnnss})\n",
        "            node_betweenness.update( {parent: node_betweenness[node] + btwnnss} )\n",
        "\n",
        "  return edges_btwnss\n",
        "\n",
        "get_edge_betweenness(subgraph, 'CAPTAIN AMERICA')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P21haE7KdnlL"
      },
      "source": [
        "def edge_betweenness(graph):\n",
        "\n",
        "  btwnss = [0] * len(graph.edges())\n",
        "\n",
        "  for node in graph.nodes():\n",
        "    btwnnss_node = get_edge_betweenness(graph, node)\n",
        "    btwnss = np.add(btwnss, list(btwnnss_node.values())) #here we are using a dict_view instead of original values\n",
        "    \n",
        "  #since dict_view has 15 significant ciphers, we will be using 14\n",
        "  btwnss = [round(score, 14) for score in btwnss]\n",
        "  btwnss_dict = dict(zip(graph.edges(), btwnss))\n",
        "  \n",
        "  return btwnss_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xrubtf4t62T"
      },
      "source": [
        "edge_betweenness(subgraph)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeuf39JZd05Z"
      },
      "source": [
        "##Girvan Newman Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRax5RVzz35h"
      },
      "source": [
        "def Girvan_Newman(graph, k):\n",
        "\n",
        "  graph_copy = graph.copy()\n",
        "\n",
        "  for iterations in tqdm(np.arange(k)):\n",
        "    betweenness = edge_betweenness(graph_copy)\n",
        "    betweenness_values = list(betweenness.values())\n",
        "\n",
        "    edges_sorted = sorted(betweenness, key=betweenness.get, reverse=True)\n",
        "    betweenness_values_sorted = sorted(betweenness_values, reverse=True)\n",
        "\n",
        "    betweenness_values_sorted.pop(0)\n",
        "    edge_to_remove = edges_sorted.pop(0)\n",
        "    print(edge_to_remove)\n",
        "    graph_copy.remove_edge(edge_to_remove[0],edge_to_remove[1])\n",
        "\n",
        "  return graph_copy\n",
        "\n",
        "###Test Code\n",
        "g = Girvan_Newman(subgraph, 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxPO1KNhWUAf"
      },
      "source": [
        "# grafo_recortado = nx.convert_matrix.to_pandas_adjacency(g)\n",
        "# grafo_recortado.to_csv('./')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaQDGjVweKbE"
      },
      "source": [
        "g.remove_edges_from(nx.selfloop_edges(g))\n",
        "net = Network(notebook=True)\n",
        "net.from_nx(g)\n",
        "net.repulsion(node_distance=300)\n",
        "net.inherit_edge_colors(True)\n",
        "\n",
        "net.save_graph('ex1.html')\n",
        "IPython.display.HTML(filename='./ex1.html')\n",
        "# nx.draw_networkx(network)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}